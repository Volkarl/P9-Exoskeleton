{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters \n",
    "# DATASET_FILE_PATH: \"BigData.xlsx\",\n",
    "# DATASET_SHEET_TITLE: \"data_test\",\n",
    "# GRANULARITY: 10, # Take first item, skip next x, take next, skip x, take next, ...\n",
    "# STEP_SIZE_SLIDING_WINDOW: 5,\n",
    "# PAST_HISTORY: 20,\n",
    "# FUTURE_TARGET: 1, \n",
    "# Looks at observations that are PASTHISTORY timesteps prior (reading only every STEP_SIZE_SLIDING_WINDOW entry),\n",
    "# then predicts the result at FUTURETARGET timesteps in the future\n",
    "# VAL_PERCENT: 0.1,\n",
    "# TEST_PERCENT: 0.1,\n",
    "# EPOCHS: 5,\n",
    "# BATCH_SIZE: 10 # Splits the dataset into batches of this size: we perform gradiant descent once per batch\n",
    "# SMOOTHING: 0\n",
    "\n",
    "# runAll(DATASET_FILE_PATH, DATASET_SHEET_TITLE, GRANULARITY, STEP_SIZE_SLIDING_WINDOW, PAST_HISTORY, \n",
    "#        FUTURE_TARGET, VAL_PERCENT, TEST_PERCENT, EPOCHS, BATCH_SPLITS_TRAIN, BATCH_SPLITS_VAL, SMOOTHING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all(DATASET_FILE_PATH, DATASET_SHEET_TITLE, GRANULARITY, STEP_SIZE_SLIDING_WINDOW, PAST_HISTORY, \n",
    "            FUTURE_TARGET, VAL_PERCENT, TEST_PERCENT, EPOCHS, BATCH_SPLITS, SMOOTHING, ATTEMPT_NAME, \n",
    "            SHUFFLE_BUFFER_SIZE, MEAN): \n",
    "    indexes, ground_truth, x_train, x_val, batched_train_data, batched_val_data, batched_test_data = process_data(\n",
    "        DATASET_FILE_PATH, DATASET_SHEET_TITLE, GRANULARITY, SMOOTHING, ATTEMPT_NAME, VAL_PERCENT, TEST_PERCENT, \n",
    "        PAST_HISTORY, FUTURE_TARGET, STEP_SIZE_SLIDING_WINDOW, BATCH_SPLITS, EPOCHS, SHUFFLE_BUFFER_SIZE, MEAN)\n",
    "    model, training_history, training_time = run_lstm(x_train, x_val, batched_train_data, batched_val_data, \n",
    "                                                      BATCH_SPLITS, EPOCHS, FUTURE_TARGET) \n",
    "    evaluate_results(model, training_history, indexes, ground_truth, batched_test_data, training_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load algorithm\n",
    "%run ./data_management_component.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./lstm_baseline.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./evaluation_component.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FILE_PATH=\"Datasets\\\\BigData.xlsx\"\n",
    "DATASET_SHEET_TITLE=\"data_test\"\n",
    "GRANULARITY=10\n",
    "STEP_SIZE_SLIDING_WINDOW=5\n",
    "PAST_HISTORY=20\n",
    "FUTURE_TARGET=1\n",
    "VAL_PERCENT=0.1\n",
    "TEST_PERCENT=0.1\n",
    "EPOCHS=5\n",
    "BATCH_SPLITS=10\n",
    "SMOOTHING=50\n",
    "ATTEMPT_NAME=\"LSTM_BASELINE\"\n",
    "SHUFFLE_BUFFER_SIZE=100\n",
    "MEAN=True\n",
    "\n",
    "# Running the algorithm all at once\n",
    "BASELINE = run_all(DATASET_FILE_PATH, DATASET_SHEET_TITLE, GRANULARITY, STEP_SIZE_SLIDING_WINDOW, \n",
    "                   PAST_HISTORY, FUTURE_TARGET, VAL_PERCENT, TEST_PERCENT, EPOCHS, BATCH_SPLITS, \n",
    "                   SMOOTHING, ATTEMPT_NAME, SHUFFLE_BUFFER_SIZE, MEAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
