{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, LSTM, Dense, Conv1D, concatenate, Flatten, Dropout\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "\n",
    "seed = 345045234\n",
    "\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "\n",
    "STEP = 10\n",
    "past_history = 1000\n",
    "future_target = 1\n",
    "\n",
    "BATCH_SIZE = 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "def multivariate_data(dataset_features, dataset_ground_truth, start_index, end_index, history_size,\n",
    "                      target_size, step, single_step=False, print_index=False):\n",
    "  data, labels, history = [], [], []\n",
    "\n",
    "  start_index = start_index + history_size \n",
    "  # such that we always have history_size (100) observations to base our predictions on\n",
    "  if end_index is None:\n",
    "    end_index = len(dataset_features) - target_size \n",
    "    # such that we never predict based on the last future_target (10) measurements\n",
    "\n",
    "  if print_index: print(\"start\")\n",
    "  for i in range(start_index, end_index): # start 100, end 790. \n",
    "      # TODO: It actually goes to 800 (when end_index is not None), meaning that our last 10 predictions cannot be verified with our training set. This is a problem\n",
    "    if print_index: print(\"A\", i,)\n",
    "    indices = range(i-history_size, i, step) # range(0, 100) step size of 1          --- our sliding window\n",
    "    data.append(dataset_features[indices]) # append new array that contains all values within our sliding window\n",
    "    # TODO: ONE PROBLEM KINDA? Step size makes no sense. Doesn't feel like there's any point to it. \n",
    "    history.append(dataset_ground_truth[indices])\n",
    "\n",
    "    if single_step:\n",
    "      labels.append(dataset_ground_truth[i+target_size])\n",
    "    else:\n",
    "      labels.append(dataset_ground_truth[i:i+target_size])\n",
    "\n",
    "  return np.array(data), np.array(labels), np.array(history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "#file_path = \"..\\\\..\\\\Datasets\\\\BigData.xlsx\"\n",
    "#data_title = \"data_test_raw_data\"\n",
    "\n",
    "file_path = \"..\\\\..\\\\Datasets\\\\uniformdata.xlsx\"\n",
    "data_title = \"data_uniformc_raw_data\"\n",
    "\n",
    "file_path3 = \"..\\\\..\\\\Datasets\\\\uniformdata.xlsx\"\n",
    "data_title3 = \"data_uniforma_raw_data\"\n",
    "\n",
    "file_path2 = \"..\\\\..\\\\Datasets\\\\uniformdata.xlsx\"\n",
    "data_title2 = \"data_uniformb_raw_data\"\n",
    "\n",
    "def thing(path,title):\n",
    "    columns_data = ['1' ,'2', '3', '4', '5', '6', '7', '8', 'N/A_1', 'N/A_2', 'angle', 'time', 'session']\n",
    "    columns_features_considered = columns_data[:8]\n",
    "    column_ground_truth = columns_data[10]\n",
    "    table_of_contents = pd.read_excel(path, sheet_name=0, header=None)\n",
    "    sheet_index = table_of_contents[table_of_contents[0] == title][0].index[0]\n",
    "    sheet_data = pd.read_excel(path, sheet_name=sheet_index + 1, header=None)\n",
    "    sheet_data.columns = columns_data\n",
    "    features = sheet_data[columns_features_considered]\n",
    "    ground_truth = pd.DataFrame(sheet_data[column_ground_truth])\n",
    "    features.plot(subplots=True)\n",
    "    ground_truth.plot()\n",
    "    dataset = features.values\n",
    "    ground_truth2 = ground_truth.values\n",
    "    xd, yd, _ = multivariate_data(dataset, ground_truth2, 0,\n",
    "                                                   None, past_history,\n",
    "                                                   future_target, STEP,\n",
    "                                                   single_step=False, print_index = False)\n",
    "    yd = np.squeeze(yd, axis=2)\n",
    "    return xd, yd\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "x_train, y_train = thing(file_path, data_title)\n",
    "x_train2, y_train2 = thing(file_path2, data_title2)\n",
    "x_test, y_test = thing(file_path3,data_title3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% MI Defines\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "print ('Single window of past history : {}'.format(x_train[0].shape))\n",
    "print(len(x_train), len(y_train))\n",
    "print(x_train.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Get training data sliding windows\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "#input\n",
    "inp = int(past_history / STEP)\n",
    "\n",
    "inputs = Input(shape=(inp,8), name='main_input')\n",
    "\n",
    "conv = Conv1D(filters=50,kernel_size=int(inp/10),strides=2,padding='same',activation='relu')(inputs)\n",
    "\n",
    "conv = Conv1D(filters=20,kernel_size=4,strides=2,padding='same',activation='relu')(conv)\n",
    "\n",
    "conv = Conv1D(filters=10,kernel_size=4,strides=2,padding='same',activation='relu')(conv)\n",
    "\n",
    "lstm = LSTM(32,return_sequences=False)(inputs) #true if deep lstm\n",
    "\n",
    "#lstm = LSTM(32)(lstm)\n",
    "\n",
    "x = Flatten()(conv)\n",
    "\n",
    "#dense_1 = Dense(32,activation='relu',name='dense1')(x)\n",
    "\n",
    "#dense_2 = Dense(32, activation='relu',name='dense2')(lstm)\n",
    "\n",
    "auxiliary_output_1 = Dense(1, name='aux_output1')(x)\n",
    "\n",
    "auxiliary_output_2 = Dense(1, name='aux_output2')(lstm)\n",
    "\n",
    "print(\"success\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "#intermediate layers\n",
    "concat = concatenate([lstm,x])\n",
    "\n",
    "x = Dense(64, activation='relu')(concat)\n",
    "#x = Dropout(rate=0.5)(x)\n",
    "#x = Dense(64, activation='relu')(x)\n",
    "#x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "main_output = Dense(1,name='main_output')(x)\n",
    "\n",
    "print('success')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "#model\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[main_output,auxiliary_output_1,auxiliary_output_2])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.01), loss={'main_output':'mae',\n",
    "                                                                          'aux_output1':'mae',\n",
    "                                                                          'aux_output2':'mae'},\n",
    "              loss_weights={'main_output':1, 'aux_output1':0.3, 'aux_output2':0.3})\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "history = model.fit({'main_input': x_train},\n",
    "          {'main_output': y_train, 'aux_output1': y_train, 'aux_output2': y_train},\n",
    "          epochs=20, batch_size=BATCH_SIZE,validation_split=0.2)\n",
    "print(\"succ\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "def plot_train_history(history, title):\n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "  epochs = range(len(loss))\n",
    "  plt.figure()\n",
    "  plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "  plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "  plt.title(title)\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "plot_train_history(history, 'Multi-Step Training and validation loss')\n",
    "\n",
    "middle_res = model.predict(x_test,batch_size=BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "history = model.fit({'main_input': x_train2},\n",
    "          {'main_output': y_train2, 'aux_output1': y_train2, 'aux_output2': y_train2},\n",
    "          epochs=5, batch_size=BATCH_SIZE,validation_split=0.2)\n",
    "\n",
    "plot_train_history(history, 'Multi-Step Training and validation loss')\n",
    "\n",
    "print(\"succ\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "print(\"start\")\n",
    "test_score = model.evaluate({'main_input': x_test},\n",
    "          {'main_output': y_test, 'aux_output1': y_test, 'aux_output2': y_test},verbose=1,batch_size=1000)\n",
    "\n",
    "print('Test loss:', test_score[0])\n",
    "print('Test accuracy:', test_score[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "res = model.predict(x_test,batch_size=BATCH_SIZE)\n",
    "res1 = res[0]\n",
    "res2 = res[1]\n",
    "res3 = res[2]\n",
    "res4 = np.mean(res,axis=0)\n",
    "\n",
    "sud = np.mean(middle_res, axis=0)\n",
    "\n",
    "print(\"succ\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "plt.plot(res1, label=\"1\")\n",
    "plt.plot(res2, label=\"2\")\n",
    "plt.plot(res3, label=\"3\")\n",
    "#plt.plot(res4, label=\"double\")\n",
    "#plt.plot(sud,label=\"single\")\n",
    "plt.plot(y_test, label=\"label\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}