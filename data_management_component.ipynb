{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(DATASET_FILE_PATH, DATASET_SHEET_TITLE, GRANULARITY, SMOOTHING, ATTEMPT_NAME, VAL_PERCENT, \n",
    "                 TEST_PERCENT, PAST_HISTORY, FUTURE_TARGET, STEP_SIZE_SLIDING_WINDOW, BATCH_SPLITS, EPOCHS, \n",
    "                 SHUFFLE_BUFFER_SIZE, MEAN):\n",
    "    raw_data = load_dataset(DATASET_FILE_PATH, DATASET_SHEET_TITLE, GRANULARITY)\n",
    "    indexes, features, ground_truth = split_data(raw_data, GRANULARITY, SMOOTHING, MEAN)\n",
    "    plot_dataset(features, ground_truth, indexes)\n",
    "    x_train, y_train, x_val, y_val, x_test, y_test = slice_data(indexes, features, ground_truth, VAL_PERCENT, \n",
    "                                                                TEST_PERCENT, PAST_HISTORY, FUTURE_TARGET, \n",
    "                                                                STEP_SIZE_SLIDING_WINDOW, GRANULARITY)\n",
    "    batched_train_data, batched_val_data, batched_test_data = batch_data(x_train, y_train, x_val, y_val, \n",
    "                                                                        x_test, y_test, BATCH_SPLITS, EPOCHS,\n",
    "                                                                        SHUFFLE_BUFFER_SIZE)\n",
    "    return indexes, ground_truth, x_train, x_val, batched_train_data, batched_val_data, batched_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definitions\n",
    "\n",
    "# Data layout in the xlsx files\n",
    "columns_data = ['1' ,'2', '3', '4', '5', '6', '7', '8', 'N/A_1', 'N/A_2', 'angle', 'time', 'session']\n",
    "columns_features_considered = columns_data[:8]\n",
    "column_ground_truth = columns_data[10]\n",
    "# Note that we ignore the 'time' column. That makes our data slightly imprecise as there are tiny, \n",
    "# TINY differences in time intervals in the real data (not worth modeling). Each timestep represents \n",
    "# 1 millisecond, 0.001 second. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(DATASET_FILE_PATH, DATASET_SHEET_TITLE, GRANULARITY):\n",
    "    # Read sheet 1 (table of contents), find index of entry with correct title, then load the corresponding excel sheet\n",
    "    table_of_contents = pd.read_excel(DATASET_FILE_PATH, sheet_name=0, header=None)\n",
    "    sheet_index = table_of_contents[table_of_contents[0] == f\"{DATASET_SHEET_TITLE}_raw_data\"][0].index[0]\n",
    "    sheet_data = pd.read_excel(DATASET_FILE_PATH, sheet_name=sheet_index + 1, header=None)\n",
    "    sheet_data.columns = columns_data\n",
    "    return sheet_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_observations(features):\n",
    "    features_len = len(features)\n",
    "    observations_len = len(features.iloc[0])\n",
    "    return pd.DataFrame([(sum(features.iloc[i]) / observations_len) for i in range(0, features_len)])\n",
    "\n",
    "def split_data(raw_data, GRANULARITY, SMOOTHING, MEAN):\n",
    "    indexes = range(0, len(raw_data), 1)[::GRANULARITY] # Each timestep is a millisecond\n",
    "    features = raw_data[columns_features_considered][::GRANULARITY].ewm(span=SMOOTHING).mean()\n",
    "    if(MEAN): features = mean_observations(features)\n",
    "    ground_truth = pd.DataFrame(raw_data[column_ground_truth][::GRANULARITY]).ewm(span=SMOOTHING).mean()\n",
    "    return indexes, features, ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dataset(features, ground_truth, indexes):\n",
    "    features.plot(subplots=True)\n",
    "    plt.show()\n",
    "    plt.plot(indexes, features.values)\n",
    "    plt.show()\n",
    "    ground_truth.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create array of all sliding windows of the data\n",
    "def multivariate_data(dataset_features, dataset_ground_truth, start_index, end_index, history_size,\n",
    "                      target_size, step, granularity, single_step=False, print_index=False):\n",
    "    data, labels = [], []\n",
    "    start_index = start_index + history_size \n",
    "    if end_index is None:\n",
    "        end_index = len(dataset_features) - target_size \n",
    "    if print_index: print(\"start\")\n",
    "    for i in range(start_index, end_index): # start 100, end 790. \n",
    "        if print_index: print(\"A\", i,)\n",
    "        indices = range(i-history_size, i, step) # range(0, 100) step size of 1          --- our sliding window\n",
    "        data.append(dataset_features[indices]) # append new array that contains all values within our sliding window\n",
    "        if single_step:\n",
    "            labels.append(dataset_ground_truth[i+target_size])\n",
    "        else:\n",
    "            labels.append(dataset_ground_truth[i:i+target_size])\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "\n",
    "def slice_data(indexes, features, ground_truth, VAL_PERCENT, TEST_PERCENT, PAST_HISTORY, FUTURE_TARGET, \n",
    "               STEP_SIZE_SLIDING_WINDOW, GRANULARITY):\n",
    "    dataset = features.values\n",
    "    observations = len(dataset)\n",
    "    train_split = int(observations * (1 - VAL_PERCENT - TEST_PERCENT))\n",
    "    val_split = int(observations * (1 - VAL_PERCENT))\n",
    "        \n",
    "    x_train, y_train = multivariate_data(dataset, ground_truth.values, 0,\n",
    "                                         train_split, PAST_HISTORY, FUTURE_TARGET, \n",
    "                                         STEP_SIZE_SLIDING_WINDOW, GRANULARITY, single_step = False, \n",
    "                                         print_index = False)\n",
    "    x_val, y_val = multivariate_data(dataset, ground_truth.values, train_split, \n",
    "                                         val_split, PAST_HISTORY, FUTURE_TARGET, \n",
    "                                         STEP_SIZE_SLIDING_WINDOW, GRANULARITY, single_step=False, \n",
    "                                         print_index = False)\n",
    "    x_test, y_test = multivariate_data(dataset, ground_truth.values, val_split, \n",
    "                                         None, PAST_HISTORY, FUTURE_TARGET, \n",
    "                                         STEP_SIZE_SLIDING_WINDOW, GRANULARITY, single_step=False, \n",
    "                                         print_index = False)\n",
    "    \n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data(x_train, y_train, x_val, y_val, x_test, y_test, BATCH_SPLITS, EPOCHS, SHUFFLE_BUFFER_SIZE):\n",
    "    batched_train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    if SHUFFLE_BUFFER_SIZE == 0:\n",
    "        batched_train_data = batched_train_data.batch(BATCH_SPLITS).repeat(EPOCHS)\n",
    "    else:\n",
    "        batched_train_data = batched_train_data.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SPLITS).repeat(EPOCHS)\n",
    "\n",
    "    batched_val_data = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(BATCH_SPLITS).repeat(EPOCHS)\n",
    "    batched_test_data = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(1) # 1 batch, no repeat\n",
    "    return batched_train_data, batched_val_data, batched_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
